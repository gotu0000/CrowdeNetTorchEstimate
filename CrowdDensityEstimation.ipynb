{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from skimage.transform import downscale_local_mean\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import h5py\n",
    "import glob\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-zQbqC9b7Fgh",
    "outputId": "fd13b6ff-0681-4e58-ee99-38c74d0cecfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUjuq4hE-ocM"
   },
   "outputs": [],
   "source": [
    "#useful for debugging\n",
    "#whenever we want to print something\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "#path for data set\n",
    "dataset_paths = ['dataset/UCF_CC_50']\n",
    "\n",
    "slice_w = 256\n",
    "slice_h = 256\n",
    "\n",
    "patch_w = 225\n",
    "patch_h = 225\n",
    "\n",
    "net_density_h = 28\n",
    "net_density_w = 28\n",
    "\n",
    "HAS_GPU = True\n",
    "GPU_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "VGG_ILSVRC_16_layers_mean = np.zeros((3, patch_h, patch_w), dtype='f4')\n",
    "VGG_ILSVRC_16_layers_mean[0,:,:] = 103.939\n",
    "VGG_ILSVRC_16_layers_mean[1,:,:] = 116.779\n",
    "VGG_ILSVRC_16_layers_mean[2,:,:] = 123.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt_from_json(gt_file, gt_shape):\n",
    "    #numpy array for ground truth \n",
    "    gt = np.zeros(gt_shape, dtype='uint8') \n",
    "    #open the file to read\n",
    "    with open(gt_file, 'r') as jf:\n",
    "        for j, dot in enumerate(json.load(jf)):\n",
    "            try:\n",
    "                #for row y\n",
    "                #for column x\n",
    "                #head annotation\n",
    "                gt[int(math.floor(dot['y'])), int(math.floor(dot['x']))] = 1\n",
    "            except IndexError:\n",
    "                print(gt_file, dot['y'], dot['x'], sys.exc_info())\n",
    "    return gt\n",
    "\n",
    "def load_images_and_gts(path):\n",
    "    images = []\n",
    "    gts = []\n",
    "    densities = []\n",
    "    for gt_file in glob.glob(os.path.join(path, '*.json')):\n",
    "        print(gt_file)\n",
    "        #read input image\n",
    "        if os.path.isfile(gt_file.replace('.json','.png')):\n",
    "            img = cv2.imread(gt_file.replace('.json','.png'))\n",
    "        else:\n",
    "            img = cv2.imread(gt_file.replace('.json','.jpg'))\n",
    "        images.append(img)\n",
    "        \n",
    "        #load corrsponding ground truth\n",
    "        gt = load_gt_from_json(gt_file, img.shape[:-1])\n",
    "        gts.append(gt)\n",
    "        \n",
    "        #densities\n",
    "        desnity_file = gt_file.replace('.json','.h5')\n",
    "        if os.path.isfile(desnity_file):\n",
    "            #load density if exist\n",
    "            with h5py.File(desnity_file, 'r') as hf:\n",
    "                density = np.array(hf.get('density'))\n",
    "        else:\n",
    "            density = gaussian_filter_density([gt])[0]\n",
    "            with h5py.File(desnity_file, 'w') as hf:\n",
    "                hf['density'] = density\n",
    "        densities.append(density)\n",
    "    print(path, len(images), 'loaded')\n",
    "    return (images, gts, densities)\n",
    "\n",
    "def density_resize(density, fx, fy):\n",
    "    return cv2.resize(density, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC)/(fx*fy)\n",
    "\n",
    "#this function just scales images \n",
    "#resizes given set of images\n",
    "#and returns list of all images\n",
    "def multiscale_pyramidal(images, gts, start=0.5, end=1.3, step=0.1):\n",
    "    frange = np.arange(start, end, step)\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    for i, img in enumerate(images):\n",
    "        for f in frange:\n",
    "            out_images.append(cv2.resize(img, None, fx=f, fy=f, interpolation = cv2.INTER_CUBIC))\n",
    "            out_gts.append(density_resize(gts[i], fx=f, fy=f))\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "def adapt_images_and_densities(images, gts, slice_w=slice_w, slice_h=slice_h):\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    for i, img in enumerate(images):\n",
    "        img_h, img_w, _ = img.shape\n",
    "        n_slices_h = int(round(img_h/slice_h))\n",
    "        n_slices_w = int(round(img_w/slice_w))\n",
    "        new_img_h = float(n_slices_h * slice_h)\n",
    "        new_img_w = float(n_slices_w * slice_w)\n",
    "        fx = new_img_w/img_w\n",
    "        fy = new_img_h/img_h\n",
    "        out_images.append(cv2.resize(img, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC))\n",
    "        assert out_images[-1].shape[0]%slice_h == 0 and out_images[-1].shape[1]%slice_w == 0\n",
    "        if gts is not None:\n",
    "            out_gts.append(density_resize(gts[i], fx, fy))\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "#Generate slices\n",
    "#like sliding window\n",
    "def generate_slices(images, gts, slice_w=slice_w, slice_h=slice_h, offset=None):\n",
    "    if offset == None:\n",
    "        offset = slice_w\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    #iterate though images\n",
    "    for i, img in enumerate(images):\n",
    "        img_h, img_w, _ = img.shape        \n",
    "        p_y_id = 0\n",
    "        p_y1 = 0\n",
    "        p_y2 = p_y1 + slice_h\n",
    "        #slide vertically\n",
    "        while p_y2 <= img_h:\n",
    "            p_x_id = 0\n",
    "            p_x1 = 0\n",
    "            p_x2 = p_x1 + slice_w\n",
    "            #slide horizontally\n",
    "            while p_x2 <= img_w:\n",
    "                out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "                assert out_images[-1].shape[:-1] == (slice_h, slice_w)\n",
    "                if gts is not None:\n",
    "                    out_gts.append(gts[i][p_y1:p_y2,p_x1:p_x2])\n",
    "                    assert out_gts[-1].shape == (slice_h, slice_w)\n",
    "                #next\n",
    "                p_x_id += 1\n",
    "                p_x1 += offset\n",
    "                p_x2 += offset\n",
    "            p_y_id += 1\n",
    "            p_y1 += offset\n",
    "            p_y2 += offset\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "#Data augmentation: CROP\n",
    "def crop_slices(images, gts):\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    for i, img in enumerate(images):\n",
    "        #data augmentation\n",
    "        #crop-5\n",
    "        img_h, img_w, _ = img.shape\n",
    "        gt = gts[i]\n",
    "        #top-left\n",
    "        p_y1, p_y2 = 0, patch_h\n",
    "        p_x1, p_x2 = 0, patch_w\n",
    "        out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "        out_gts.append(gt[p_y1:p_y2,p_x1:p_x2])\n",
    "        #top-right\n",
    "        p_y1, p_y2 = 0, patch_h\n",
    "        p_x1, p_x2 = img_w-patch_w, img_w\n",
    "        out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "        out_gts.append(gt[p_y1:p_y2,p_x1:p_x2])\n",
    "        #bottom-left\n",
    "        p_y1, p_y2 = img_h-patch_h, img_h\n",
    "        p_x1, p_x2 = 0, patch_w\n",
    "        out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "        out_gts.append(gt[p_y1:p_y2,p_x1:p_x2])\n",
    "        #bottom-right\n",
    "        p_y1, p_y2 = img_h-patch_h, img_h\n",
    "        p_x1, p_x2 = img_w-patch_w, img_w\n",
    "        out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "        out_gts.append(gt[p_y1:p_y2,p_x1:p_x2])\n",
    "        #center\n",
    "        p_y1, p_y2 = int((img_h-patch_h)/2), int((img_h-patch_h)/2)+patch_h\n",
    "        p_x1, p_x2 = int((img_w-patch_w)/2), int((img_w-patch_w)/2)+patch_w\n",
    "        out_images.append(img[p_y1:p_y2,p_x1:p_x2])\n",
    "        out_gts.append(gt[p_y1:p_y2,p_x1:p_x2])\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "\n",
    "#Data augmentation: FLIP\n",
    "def flip_slices(images, gts):\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    for i, img in enumerate(images):\n",
    "        img_h, img_w, _ = img.shape\n",
    "        gt = gts[i]\n",
    "        #original images\n",
    "        out_images.append(img)\n",
    "        out_gts.append(gt)\n",
    "        #flip: left-right\n",
    "        out_images.append(np.fliplr(img))\n",
    "        out_gts.append(np.fliplr(gt))\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "#Shuffling\n",
    "def shuffle_slices(images, gts):\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    index_shuf = list(range(len(images)))\n",
    "    shuffle(index_shuf)\n",
    "    for i in index_shuf:\n",
    "        out_images.append(images[i])\n",
    "        out_gts.append(gts[i])\n",
    "    return (out_images, out_gts)\n",
    "\n",
    "def samples_distribution(images, gts):\n",
    "    out_images = []\n",
    "    out_gts = []\n",
    "    gts_count = list(map(np.sum, gts))\n",
    "    max_count = max(gts_count)\n",
    "    #pos\n",
    "    for i, img in enumerate(images):\n",
    "        if gts_count[i] >= 1. and random.random() < gts_count[i]**2/max_count**2:\n",
    "            out_images.append(img)\n",
    "            out_gts.append(gts[i])\n",
    "    #neg\n",
    "    neg_count = sum(gt_count < 1. for gt_count in gts_count)\n",
    "    obj_neg_count = len(out_gts) / 6 # ~= 15-16%\n",
    "    neg_keep_prob = min(1., float(obj_neg_count) / float(neg_count))\n",
    "    for i, img in enumerate(images):\n",
    "        if gts_count[i] < 1. and random.random() < neg_keep_prob:\n",
    "            out_images.append(img)\n",
    "            out_gts.append(gts[i])\n",
    "        \n",
    "    return (out_images, out_gts)\n",
    "\n",
    "#to generate densities as a label\n",
    "def gaussian_filter_density(gts):\n",
    "    densities = []\n",
    "    for gt in gts:\n",
    "        print(gt.shape)\n",
    "        density = np.zeros(gt.shape, dtype=np.float32)\n",
    "        gt_count = np.count_nonzero(gt)\n",
    "        if gt_count == 0:\n",
    "            return density\n",
    "\n",
    "        pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))\n",
    "        leafsize = 2048\n",
    "        # build kdtree\n",
    "        #print 'build kdtree...'\n",
    "        tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
    "        # query kdtree\n",
    "        #print 'query kdtree...' \n",
    "        distances, locations = tree.query(pts, k=2, eps=10.)\n",
    "\n",
    "        #print 'generate density...'\n",
    "        \n",
    "        for i, pt in enumerate(pts):\n",
    "            pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
    "            pt2d[pt[1],pt[0]] = 1.\n",
    "            if gt_count > 1:\n",
    "                sigma = distances[i][1]\n",
    "            else:\n",
    "                sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
    "            density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
    "        #print 'done.'\n",
    "        densities.append(density)\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/UCF_CC_50/16.json\n",
      "dataset/UCF_CC_50/3.json\n",
      "dataset/UCF_CC_50/45.json\n",
      "dataset/UCF_CC_50/18.json\n",
      "dataset/UCF_CC_50/4.json\n",
      "dataset/UCF_CC_50/41.json\n",
      "dataset/UCF_CC_50/23.json\n",
      "dataset/UCF_CC_50/39.json\n",
      "dataset/UCF_CC_50/21.json\n",
      "dataset/UCF_CC_50/24.json\n",
      "dataset/UCF_CC_50/28.json\n",
      "dataset/UCF_CC_50/27.json\n",
      "dataset/UCF_CC_50/43.json\n",
      "dataset/UCF_CC_50/38.json\n",
      "dataset/UCF_CC_50/5.json\n",
      "dataset/UCF_CC_50/22.json\n",
      "dataset/UCF_CC_50/48.json\n",
      "dataset/UCF_CC_50/6.json\n",
      "dataset/UCF_CC_50/36.json\n",
      "dataset/UCF_CC_50/25.json\n",
      "dataset/UCF_CC_50/9.json\n",
      "dataset/UCF_CC_50/34.json\n",
      "dataset/UCF_CC_50/8.json\n",
      "dataset/UCF_CC_50/35.json\n",
      "dataset/UCF_CC_50/49.json\n",
      "dataset/UCF_CC_50/30.json\n",
      "dataset/UCF_CC_50/37.json\n",
      "dataset/UCF_CC_50/44.json\n",
      "dataset/UCF_CC_50/26.json\n",
      "dataset/UCF_CC_50/10.json\n",
      "dataset/UCF_CC_50/42.json\n",
      "dataset/UCF_CC_50/46.json\n",
      "dataset/UCF_CC_50/29.json\n",
      "dataset/UCF_CC_50/33.json\n",
      "dataset/UCF_CC_50/31.json\n",
      "dataset/UCF_CC_50/19.json\n",
      "dataset/UCF_CC_50/11.json\n",
      "dataset/UCF_CC_50/47.json\n",
      "dataset/UCF_CC_50/13.json\n",
      "dataset/UCF_CC_50/50.json\n",
      "dataset/UCF_CC_50/40.json\n",
      "dataset/UCF_CC_50/14.json\n",
      "dataset/UCF_CC_50/32.json\n",
      "dataset/UCF_CC_50/12.json\n",
      "dataset/UCF_CC_50/7.json\n",
      "dataset/UCF_CC_50/15.json\n",
      "dataset/UCF_CC_50/2.json\n",
      "dataset/UCF_CC_50 47 loaded\n"
     ]
    }
   ],
   "source": [
    "# Positive image and ground truth loading\n",
    "X_fs = []\n",
    "Y_fs = []\n",
    "\n",
    "for path in dataset_paths:\n",
    "    images, gts, densities = load_images_and_gts(path)\n",
    "    X_fs += images\n",
    "    Y_fs += densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 800)\n",
      "(752, 1024)\n",
      "(600, 896)\n",
      "(768, 1024)\n",
      "(680, 1024)\n",
      "(656, 1024)\n",
      "(656, 1024)\n",
      "(680, 1024)\n",
      "(1024, 680)\n",
      "(648, 1024)\n",
      "(680, 1024)\n",
      "(432, 1024)\n",
      "(496, 744)\n",
      "(328, 496)\n",
      "(424, 640)\n",
      "(680, 1024)\n",
      "(768, 1024)\n",
      "(768, 1024)\n",
      "(768, 1024)\n",
      "(712, 1024)\n",
      "(768, 1024)\n",
      "(768, 1024)\n",
      "(768, 1024)\n",
      "(768, 1024)\n",
      "(1024, 1024)\n",
      "(480, 640)\n",
      "(768, 1024)\n",
      "(680, 1024)\n",
      "(712, 1024)\n",
      "(448, 640)\n",
      "(600, 456)\n",
      "(656, 1024)\n",
      "(680, 1024)\n",
      "(424, 720)\n",
      "(680, 1024)\n",
      "(496, 360)\n",
      "(744, 1024)\n",
      "(600, 800)\n",
      "(680, 1024)\n",
      "(440, 640)\n",
      "(768, 1024)\n",
      "(680, 1024)\n",
      "(680, 1024)\n",
      "(824, 1024)\n",
      "(424, 600)\n",
      "(528, 640)\n",
      "(680, 1024)\n"
     ]
    }
   ],
   "source": [
    "for i in Y_fs:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiscale pyramidal\n",
      "TRAIN:\n",
      "296 296\n",
      "TEST:\n",
      "80 80\n",
      "\n",
      "Generate slices\n",
      "TRAIN:\n",
      "1066861 1066861\n",
      "TEST:\n",
      "559 559\n",
      "\n",
      "Flip\n",
      "TRAIN:\n",
      "2133722 2133722\n",
      "TEST:\n",
      "1118 1118\n",
      "\n",
      "Samples gt distribution correction\n",
      "TRAIN:\n",
      "33006 33006\n",
      "\n",
      "Shuffle\n",
      "TRAIN:\n",
      "33006 33006\n",
      "TEST:\n",
      "1118 1118\n"
     ]
    }
   ],
   "source": [
    "# Split test an train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train 80%, Test 20%\n",
    "X_fs_train, X_fs_test, Y_fs_train, Y_fs_test = train_test_split(X_fs, Y_fs, test_size=0.2)\n",
    "\n",
    "# FS: FULL SIZE\n",
    "X_train, Y_train = X_fs_train, Y_fs_train\n",
    "X_test, Y_test = X_fs_test, Y_fs_test\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "print('\\nMultiscale pyramidal')\n",
    "print('TRAIN:')\n",
    "X_train, Y_train = multiscale_pyramidal(X_train, Y_train)\n",
    "print(len(X_train), len(Y_train))\n",
    "print('TEST:')\n",
    "X_test, Y_test = multiscale_pyramidal(X_test, Y_test)\n",
    "print(len(X_test), len(Y_test))\n",
    "\n",
    "# PATCH SIZE\n",
    "print('\\nGenerate slices')\n",
    "print('TRAIN:')\n",
    "X_train, Y_train = generate_slices(X_train, Y_train, slice_w=patch_w, slice_h=patch_h, offset=8)\n",
    "print(len(X_train), len(Y_train))\n",
    "print('TEST:')\n",
    "X_test, Y_test = generate_slices(X_test, Y_test, slice_w=patch_w, slice_h=patch_h)\n",
    "print(len(X_test), len(Y_test))\n",
    "\n",
    "print('\\nFlip')\n",
    "print('TRAIN:')\n",
    "X_train, Y_train = flip_slices(X_train, Y_train)\n",
    "print(len(X_train), len(Y_train))\n",
    "print('TEST:')\n",
    "X_test, Y_test = flip_slices(X_test, Y_test)\n",
    "print(len(X_test), len(Y_test))\n",
    "\n",
    "print('\\nSamples gt distribution correction')\n",
    "print('TRAIN:')\n",
    "X_train, Y_train = samples_distribution(X_train, Y_train)\n",
    "print(len(X_train), len(Y_train))\n",
    "\n",
    "\n",
    "print('\\nShuffle')\n",
    "print('TRAIN:')\n",
    "X_train, Y_train = shuffle_slices(X_train, Y_train)\n",
    "print(len(X_train), len(Y_train))\n",
    "print('TEST:')\n",
    "X_test, y_test = shuffle_slices(X_test, Y_test)\n",
    "print(len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "#convert to float\n",
    "# X_train = np.float32(X_train)\n",
    "# X_train = X_train/255.0\n",
    "\n",
    "X_train = X_train.transpose(0, 3, 1, 2)\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_train = np.reshape(Y_train,(Y_train.shape[0],1,Y_train.shape[1],Y_train.shape[2]))\n",
    "Y_train_tensor = torch.from_numpy(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test)\n",
    "X_test = X_test.transpose(0, 3, 1, 2)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "\n",
    "Y_test = np.asarray(Y_test)\n",
    "Y_test = np.reshape(Y_test,(Y_test.shape[0],1,Y_test.shape[1],Y_test.shape[2]))\n",
    "Y_test_tensor = torch.from_numpy(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FdnK0-h-993"
   },
   "outputs": [],
   "source": [
    "#our module should subclass this class\n",
    "#every network we make should be inherited by \"nn.Module\"\n",
    "class CrowdNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrowdNet, self).__init__()\n",
    "        # 3 image input channel, 64 filters, 3x3 kernel\n",
    "        # stack them sequentially\n",
    "        self.deepConvNet = nn.Sequential(\n",
    "            # c1\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3),padding=1),\n",
    "            # relu1\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            \n",
    "            # c2\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3),padding=1), \n",
    "            # relu2\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            # first pooling layer\n",
    "            # s1\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),  \n",
    "            \n",
    "            # c3\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3),padding=1),\n",
    "            # relu3\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            # c4\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3),padding=1),\n",
    "            # relu4s\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            # second pooling layer\n",
    "            # s2\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # c5\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3),padding=1),\n",
    "            # relu5\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c6\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3),padding=1),\n",
    "            # relu6\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c7\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3),padding=1),\n",
    "            # relu7\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # third pooling layer\n",
    "            # s3\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # c8\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu8\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c9\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu9\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c10\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu10\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # fourth pooling layer\n",
    "            # s4\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1),\n",
    "            \n",
    "            # c11\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu11\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c12\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu12\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # c13\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3),padding=1),\n",
    "            # relu13\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.shallowConvNet = nn.Sequential(\n",
    "            # c1\n",
    "            nn.Conv2d(3, 24, kernel_size=(5, 5),padding=2),\n",
    "            # relu1\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #average pooling layer 1\n",
    "            nn.AvgPool2d(kernel_size=(5, 5), stride=2),\n",
    "            \n",
    "            # c2\n",
    "            nn.Conv2d(24, 24, kernel_size=(5, 5),padding=2),\n",
    "            # relu2\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #average pooling layer 2\n",
    "            nn.AvgPool2d(kernel_size=(5, 5), stride=2),\n",
    "            \n",
    "            # c3\n",
    "            nn.Conv2d(24, 24, kernel_size=(5, 5),padding=3),\n",
    "            # relu3\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            #average pooling layer 3\n",
    "            nn.AvgPool2d(kernel_size=(5, 5), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.interpConvNet = nn.Sequential(\n",
    "            # c1\n",
    "            nn.Conv2d(536, 1, kernel_size=(1, 1)),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        deepConvOut = self.deepConvNet(input)\n",
    "        shallowConvOut = self.shallowConvNet(input)\n",
    "        #concatanate two layers\n",
    "        concOut = torch.cat((deepConvOut, shallowConvOut), 1)\n",
    "        \n",
    "        interpOut = self.interpConvNet(concOut)\n",
    "        \n",
    "        inputW = input.size()[2]\n",
    "        inputH = input.size()[3]\n",
    "        \n",
    "        #scale up the image \n",
    "        scaleUp = nn.Upsample(size=(inputW,inputH), mode='bilinear',align_corners = True)\n",
    "        scaledInterpOut = scaleUp(interpOut)\n",
    "        return scaledInterpOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 2e-3\n",
    "\n",
    "# model = CrowdNet().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# a = np.zeros((496,744,3),dtype='float32')\n",
    "# print(a.shape)\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# a = torch.from_numpy(a)\n",
    "# a = a.to(device)\n",
    "# a = a.view(1,a.size()[2],a.size()[0],a.size()[1])\n",
    "# outputs = model(a)\n",
    "# print(outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efhiZEMgRgov"
   },
   "outputs": [],
   "source": [
    "#define model related constants\n",
    "num_epochs = 30\n",
    "batch_size_train = 16\n",
    "batch_size_test = 16\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = CrowdNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59905024\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "#loaders for mini batch\n",
    "crowd_count_dataset = utils.TensorDataset(X_train_tensor,Y_train_tensor) # create your datset\n",
    "crowd_count_trainloader = utils.DataLoader(crowd_count_dataset, batch_size=batch_size_train, shuffle=False) # create your dataloader\n",
    "\n",
    "crowd_count_dataset_test = utils.TensorDataset(X_test_tensor,Y_test_tensor) # create your datset\n",
    "crowd_count_testloader = utils.DataLoader(crowd_count_dataset_test, batch_size=batch_size_test, shuffle=False) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_num):\n",
    "    for i, (images, labels) in enumerate(crowd_count_trainloader):\n",
    "        images = images.to(device).type(dtype)\n",
    "#         images = images/255.0\n",
    "        labels = labels.to(device).type(dtype)\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(images) \n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.8f'\n",
    "                  % (epoch_num + 1, num_epochs, i + 1,\n",
    "                     len(crowd_count_dataset) // batch_size_train, loss.item()))\n",
    "#         print(torch.cuda.memory_allocated(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_error(loader, length, split='validation'):\n",
    "    \"\"\" Computes the loss for all data points in a loader.\n",
    "       \n",
    "        Inputs:\n",
    "            loader: Pytorch data loader (object)\n",
    "            length: Number of data points (integer)\n",
    "            split: Name of split, typically 'train', 'test', or 'validation' (string)\n",
    "        \n",
    "        Returns:\n",
    "            loss (floating point)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Measure the error for the entire loader split.\n",
    "    i = 0\n",
    "    loss = 0.\n",
    "    num_batches = 0\n",
    "    for images, labels in loader:  # One batch at a time!\n",
    "        images = images.to(device).type(dtype)\n",
    "#         images = images/255.0\n",
    "        labels = labels.to(device).type(dtype)\n",
    "        outputs = model(images)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "        # print(f'Batch loss is {criterion(outputs, labels)}')\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f'Error of the model on the {length} {split} images: {loss / num_batches: .6f}')\n",
    "    return loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainError = []\n",
    "testError = []\n",
    "def run_training():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(epoch)\n",
    "        #store the model also\n",
    "        modelStr = \"./LastSavedDSParam_%d.pt\"%epoch\n",
    "        torch.save(model.state_dict(), modelStr)\n",
    "        temp = epoch_error(crowd_count_trainloader, len(crowd_count_dataset), 'train')\n",
    "        trainError.append(temp)\n",
    "        temp = epoch_error(crowd_count_testloader, len(crowd_count_dataset_test), 'test')\n",
    "        testError.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59905024\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 30], Step: [ 10/ 2062], Loss: 0.02440552\n",
      "Epoch: [ 1/ 30], Step: [ 20/ 2062], Loss: 0.00198729\n",
      "Epoch: [ 1/ 30], Step: [ 30/ 2062], Loss: 0.00392830\n",
      "Epoch: [ 1/ 30], Step: [ 40/ 2062], Loss: 0.00190447\n",
      "Epoch: [ 1/ 30], Step: [ 50/ 2062], Loss: 0.00109336\n",
      "Epoch: [ 1/ 30], Step: [ 60/ 2062], Loss: 0.00105917\n",
      "Epoch: [ 1/ 30], Step: [ 70/ 2062], Loss: 0.00070538\n",
      "Epoch: [ 1/ 30], Step: [ 80/ 2062], Loss: 0.00076102\n",
      "Epoch: [ 1/ 30], Step: [ 90/ 2062], Loss: 0.00068463\n",
      "Epoch: [ 1/ 30], Step: [ 100/ 2062], Loss: 0.00105097\n",
      "Epoch: [ 1/ 30], Step: [ 110/ 2062], Loss: 0.00072174\n",
      "Epoch: [ 1/ 30], Step: [ 120/ 2062], Loss: 0.00052875\n",
      "Epoch: [ 1/ 30], Step: [ 130/ 2062], Loss: 0.00048468\n",
      "Epoch: [ 1/ 30], Step: [ 140/ 2062], Loss: 0.00071840\n"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_fs)):\n",
    "    print(Y_fs[i].shape)\n",
    "    print(np.sum(Y_fs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model.eval()\n",
    "for images in X_fs:\n",
    "    temp = torch.from_numpy(images)\n",
    "    temp = temp.to(device).type(dtype)\n",
    "    temp = temp.view(1,temp.size()[2],temp.size()[0],temp.size()[1])\n",
    "    outputs = model(temp)\n",
    "    print(outputs.size())\n",
    "#     print(torch.sum(outputs))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CrowdDensityEstimation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
